# C-FTS: Monocular Video 3D Human Pose Estimation Based on Cross-Attention of Frequency, Time and Space Domains

This is the official implementation of "Monocular Video 3D Human Pose Estimation Based on Cross-Attention of Frequency, Time and Space Domains" on PyTorch platform.

## Demo
<div align=center>

![kunkun](video_1.gif)
![myVideo](video_2.gif)

</div>

## The released codes include:
Updating...

## Environment
Make sure you have the following dependencies installed:
* PyTorch >= 0.4.0
* NumPy
* Matplotlib=3.1.0
> Our environment configuration is given in ```environment.yaml```, which can be used as a reference.

## Datasets

- [Human3.6M](http://vision.imar.ro/human3.6m): We set up the Human3.6M dataset in the same way as [VideoPose3D](https://github.com/facebookresearch/VideoPose3D/blob/master/DATASETS.md). 
- [MPI-INF-3DHP](https://vcai.mpi-inf.mpg.de/3dhp-dataset/): We set up the MPI-INF-3DHP dataset in the same way as [P-STMO](https://github.com/paTRICK-swk/P-STMO). 



## Training 
Updating...


## Evaluation
Updating...

## Inference
Updating...

## Citation

If you find this repo useful, please consider citing our paper:...

## Acknowledgement
Our code refers to the following repositories. We thank the authors for releasing the codes.

- [VideoPose3D](https://github.com/facebookresearch/VideoPose3D) 
- [StridedTransformer-Pose3D](https://github.com/Vegetebird/StridedTransformer-Pose3D) 
- [P-STMO](https://github.com/paTRICK-swk/P-STMO/tree/main) 
- [MHFormer](https://github.com/Vegetebird/MHFormer) 
- [MixSTE](https://github.com/JinluZhang1126/MixSTE) 
- [FTCM](https://github.com/zhenhuat/FTCM)
- [STCFormer](https://github.com/zhenhuat/STCFormer)

